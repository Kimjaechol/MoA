/**
 * MoA SLM Auto-Installer
 *
 * ì»´ë§¹ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì›í´ë¦­ ìë™ ì„¤ì¹˜ ì‹œìŠ¤í…œ
 * MoA ì—ì´ì „íŠ¸ ì„¤ì¹˜ ì‹œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìë™ìœ¼ë¡œ ì‹¤í–‰ë¨
 *
 * Features:
 * - Ollama ìë™ ê°ì§€ ë° ì„¤ì¹˜
 * - SLM ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ (Q4_K_M)
 * - ì‚¬ìš©ì ì¹œí™”ì  ì§„í–‰ë¥  í‘œì‹œ
 * - ì—ëŸ¬ ìë™ ë³µêµ¬ ë° ì¬ì‹œë„
 * - ë””ë°”ì´ìŠ¤ ë©”ëª¨ë¦¬ ìë™ ê°ì§€
 */

import { spawn, exec } from "child_process";
import * as fs from "fs";
import * as os from "os";
import * as path from "path";
import { promisify } from "util";

const execAsync = promisify(exec);

// ============================================
// Types
// ============================================

export interface AutoInstallConfig {
  /** ì„¤ì¹˜ ëª¨ë“œ */
  mode: "full" | "minimal" | "auto";
  /** ì§„í–‰ ìƒí™© ì½œë°± */
  onProgress?: (status: InstallStatus) => void;
  /** ì™„ë£Œ ì½œë°± */
  onComplete?: (result: InstallResult) => void;
  /** ì—ëŸ¬ ì½œë°± */
  onError?: (error: Error) => void;
  /** ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì—¬ë¶€ */
  background?: boolean;
  /** ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼ í‘œì‹œ ì—¬ë¶€ */
  showNotifications?: boolean;
}

export interface InstallStatus {
  /** ì „ì²´ ì§„í–‰ë¥  (0-100) */
  progress: number;
  /** í˜„ì¬ ë‹¨ê³„ */
  step: InstallStep;
  /** ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ */
  message: string;
  /** ìƒì„¸ ë©”ì‹œì§€ (ê¸°ìˆ ì ) */
  detail?: string;
  /** ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ (ì´ˆ) */
  estimatedTimeRemaining?: number;
}

export type InstallStep =
  | "preparing" // ì¤€ë¹„ ì¤‘
  | "checking" // ì‹œìŠ¤í…œ í™•ì¸
  | "downloading" // Ollama ë‹¤ìš´ë¡œë“œ
  | "installing" // Ollama ì„¤ì¹˜
  | "starting" // ì„œë²„ ì‹œì‘
  | "model-tier1" // Tier 1 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
  | "model-tier2" // Tier 2 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
  | "verifying" // ì„¤ì¹˜ í™•ì¸
  | "complete" // ì™„ë£Œ
  | "error"; // ì—ëŸ¬

export interface InstallResult {
  success: boolean;
  tier1Installed: boolean;
  tier2Installed: boolean;
  ollamaVersion?: string;
  error?: string;
  duration: number; // ì†Œìš” ì‹œê°„ (ms)
}

// ============================================
// Constants
// ============================================

const OLLAMA_API = "http://127.0.0.1:11434";
const MAX_RETRIES = 3;
const RETRY_DELAY = 2000;

// ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€
const USER_MESSAGES: Record<InstallStep, string> = {
  preparing: "ğŸš€ MoA AI ì¤€ë¹„ ì¤‘...",
  checking: "ğŸ” ì‹œìŠ¤í…œ í™•ì¸ ì¤‘...",
  downloading: "â¬‡ï¸ AI ì—”ì§„ ë‹¤ìš´ë¡œë“œ ì¤‘...",
  installing: "ğŸ“¦ AI ì—”ì§„ ì„¤ì¹˜ ì¤‘...",
  starting: "ğŸ”„ AI ì„œë²„ ì‹œì‘ ì¤‘...",
  "model-tier1": "ğŸ§  ê¸°ë³¸ AI ëª¨ë¸ ì„¤ì¹˜ ì¤‘...",
  "model-tier2": "ğŸ“ ê³ ê¸‰ AI ëª¨ë¸ ì„¤ì¹˜ ì¤‘...",
  verifying: "âœ… ì„¤ì¹˜ í™•ì¸ ì¤‘...",
  complete: "ğŸ‰ MoA AI ì„¤ì¹˜ ì™„ë£Œ!",
  error: "âŒ ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
};

// ë‹¨ê³„ë³„ ì§„í–‰ë¥ 
const STEP_PROGRESS: Record<InstallStep, number> = {
  preparing: 0,
  checking: 5,
  downloading: 15,
  installing: 30,
  starting: 40,
  "model-tier1": 60,
  "model-tier2": 85,
  verifying: 95,
  complete: 100,
  error: -1,
};

// ============================================
// Device Detection
// ============================================

interface DeviceProfile {
  type: "mobile" | "tablet" | "desktop" | "server";
  totalMemoryGB: number;
  availableMemoryGB: number;
  cpuCores: number;
  canRunTier2: boolean;
  recommendedMode: "full" | "minimal";
}

function detectDevice(): DeviceProfile {
  const totalMemoryGB = os.totalmem() / 1024 ** 3;
  const freeMemoryGB = os.freemem() / 1024 ** 3;
  const cpuCores = os.cpus().length;

  // ë””ë°”ì´ìŠ¤ íƒ€ì… ì¶”ì •
  let type: DeviceProfile["type"] = "desktop";
  if (totalMemoryGB < 4) {
    type = "mobile";
  } else if (totalMemoryGB < 8) {
    type = "tablet";
  } else if (cpuCores >= 8 && totalMemoryGB >= 32) {
    type = "server";
  }

  // Tier 2 ì‹¤í–‰ ê°€ëŠ¥ ì—¬ë¶€ (ìµœì†Œ 6GB RAM)
  const canRunTier2 = totalMemoryGB >= 6;

  return {
    type,
    totalMemoryGB: Math.round(totalMemoryGB * 10) / 10,
    availableMemoryGB: Math.round(freeMemoryGB * 10) / 10,
    cpuCores,
    canRunTier2,
    recommendedMode: canRunTier2 ? "full" : "minimal",
  };
}

// ============================================
// Ollama Management
// ============================================

async function isOllamaInstalled(): Promise<boolean> {
  try {
    await execAsync("ollama --version");
    return true;
  } catch {
    return false;
  }
}

async function isOllamaRunning(): Promise<boolean> {
  try {
    const response = await fetch(`${OLLAMA_API}/api/tags`, {
      signal: AbortSignal.timeout(2000),
    });
    return response.ok;
  } catch {
    return false;
  }
}

async function getOllamaVersion(): Promise<string | null> {
  try {
    const { stdout } = await execAsync("ollama --version");
    return stdout.trim().replace("ollama version ", "");
  } catch {
    return null;
  }
}

async function installOllamaAuto(onProgress: (detail: string) => void): Promise<boolean> {
  const platform = os.platform();

  try {
    if (platform === "darwin") {
      // macOS: Homebrew ë˜ëŠ” ê³µì‹ ìŠ¤í¬ë¦½íŠ¸
      onProgress("macOSìš© Ollama ì„¤ì¹˜ ì¤‘...");
      try {
        await execAsync("brew install ollama", { timeout: 300000 });
      } catch {
        await execAsync("curl -fsSL https://ollama.com/install.sh | sh", {
          timeout: 300000,
        });
      }
    } else if (platform === "linux") {
      // Linux: ê³µì‹ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
      onProgress("Linuxìš© Ollama ì„¤ì¹˜ ì¤‘...");
      await execAsync("curl -fsSL https://ollama.com/install.sh | sh", {
        timeout: 300000,
      });
    } else if (platform === "win32") {
      // Windows: ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ë‹¤ìš´ë¡œë“œ ë° ì‹¤í–‰
      onProgress("Windowsìš© Ollama ë‹¤ìš´ë¡œë“œ ì¤‘...");
      const installerUrl = "https://ollama.com/download/OllamaSetup.exe";
      const installerPath = path.join(os.tmpdir(), "OllamaSetup.exe");

      // PowerShellë¡œ ë‹¤ìš´ë¡œë“œ
      await execAsync(
        `powershell -Command "Invoke-WebRequest -Uri '${installerUrl}' -OutFile '${installerPath}'"`,
        { timeout: 300000 },
      );

      onProgress("Ollama ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘...");
      await execAsync(`"${installerPath}" /S`, { timeout: 120000 });

      // ì •ë¦¬
      try {
        fs.unlinkSync(installerPath);
      } catch {
        // ë¬´ì‹œ
      }
    } else {
      throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ìš´ì˜ì²´ì œ: ${platform}`);
    }

    return await isOllamaInstalled();
  } catch (error) {
    console.error("Ollama ì„¤ì¹˜ ì‹¤íŒ¨:", error);
    return false;
  }
}

async function startOllamaServer(onProgress: (detail: string) => void): Promise<boolean> {
  if (await isOllamaRunning()) {
    onProgress("Ollama ì„œë²„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤");
    return true;
  }

  onProgress("Ollama ì„œë²„ ì‹œì‘ ì¤‘...");

  // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì„œë²„ ì‹œì‘
  const child = spawn("ollama", ["serve"], {
    detached: true,
    stdio: "ignore",
  });
  child.unref();

  // ì„œë²„ ì‹œì‘ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
  for (let i = 0; i < 60; i++) {
    await sleep(500);
    if (await isOllamaRunning()) {
      onProgress("Ollama ì„œë²„ ì‹œì‘ ì™„ë£Œ");
      return true;
    }
  }

  return false;
}

// ============================================
// Model Management
// ============================================

interface ModelDownloadProgress {
  model: string;
  status: string;
  completed: number;
  total: number;
  percent: number;
}

async function downloadModel(
  modelName: string,
  onProgress: (progress: ModelDownloadProgress) => void,
): Promise<boolean> {
  try {
    const response = await fetch(`${OLLAMA_API}/api/pull`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ name: modelName, stream: true }),
    });

    if (!response.ok || !response.body) {
      throw new Error(`ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ${response.statusText}`);
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
      const { done, value } = await reader.read();
      if (done) {
        break;
      }

      const lines = decoder.decode(value).split("\n").filter(Boolean);
      for (const line of lines) {
        try {
          const data = JSON.parse(line) as {
            status?: string;
            completed?: number;
            total?: number;
            error?: string;
          };

          if (data.error) {
            throw new Error(data.error);
          }

          const completed = data.completed || 0;
          const total = data.total || 1;
          const percent = Math.round((completed / total) * 100);

          onProgress({
            model: modelName,
            status: data.status || "ë‹¤ìš´ë¡œë“œ ì¤‘",
            completed,
            total,
            percent,
          });
        } catch {
          // JSON íŒŒì‹± ì—ëŸ¬ ë¬´ì‹œ
        }
      }
    }

    return true;
  } catch (error) {
    console.error(`ëª¨ë¸ ${modelName} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨:`, error);
    return false;
  }
}

async function isModelInstalled(modelName: string): Promise<boolean> {
  try {
    const response = await fetch(`${OLLAMA_API}/api/tags`);
    if (!response.ok) {
      return false;
    }

    const data = (await response.json()) as { models?: Array<{ name: string }> };
    const baseModel = modelName.split(":")[0];
    return data.models?.some((m) => m.name.startsWith(baseModel)) || false;
  } catch {
    return false;
  }
}

// ============================================
// Auto-Installer
// ============================================

/**
 * MoA SLM ì›í´ë¦­ ìë™ ì„¤ì¹˜
 *
 * ì»´ë§¹ ì‚¬ìš©ìë„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡
 * ëª¨ë“  ê³¼ì •ì´ ìë™ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.
 */
export async function autoInstallSLM(
  config: AutoInstallConfig = { mode: "auto" },
): Promise<InstallResult> {
  const startTime = Date.now();
  const device = detectDevice();

  // ì„¤ì¹˜ ëª¨ë“œ ê²°ì •
  const installMode = config.mode === "auto" ? device.recommendedMode : config.mode;

  const notify = (step: InstallStep, detail?: string, subProgress?: number) => {
    const baseProgress = STEP_PROGRESS[step];
    const nextStep = getNextStep(step);
    const nextProgress = nextStep ? STEP_PROGRESS[nextStep] : 100;
    const stepRange = nextProgress - baseProgress;

    const progress =
      subProgress !== undefined ? baseProgress + (stepRange * subProgress) / 100 : baseProgress;

    config.onProgress?.({
      progress: Math.round(progress),
      step,
      message: USER_MESSAGES[step],
      detail,
    });
  };

  try {
    // Step 1: ì¤€ë¹„
    notify("preparing");
    await sleep(500);

    // Step 2: ì‹œìŠ¤í…œ í™•ì¸
    notify("checking", `ë””ë°”ì´ìŠ¤: ${device.type}, ë©”ëª¨ë¦¬: ${device.totalMemoryGB}GB`);

    const ollamaInstalled = await isOllamaInstalled();
    const ollamaRunning = await isOllamaRunning();

    // Step 3: Ollama ì„¤ì¹˜ (í•„ìš”ì‹œ)
    if (!ollamaInstalled) {
      notify("downloading");

      const installed = await retryWithBackoff(
        () => installOllamaAuto((detail) => notify("installing", detail)),
        MAX_RETRIES,
      );

      if (!installed) {
        throw new Error("Ollama ì„¤ì¹˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.");
      }
    } else {
      notify("installing", "Ollamaê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤");
    }

    // Step 4: ì„œë²„ ì‹œì‘
    notify("starting");

    if (!ollamaRunning) {
      const started = await startOllamaServer((detail) => notify("starting", detail));
      if (!started) {
        throw new Error("Ollama ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
      }
    }

    // Step 5: Tier 1 ëª¨ë¸ ì„¤ì¹˜
    notify("model-tier1", "Qwen3-0.6B (ì—ì´ì „íŠ¸ ì½”ì–´) ë‹¤ìš´ë¡œë“œ ì¤‘...");

    const tier1Model = "qwen3:0.6b-q4_K_M";
    let tier1Installed = await isModelInstalled(tier1Model);

    if (!tier1Installed) {
      tier1Installed = await downloadModel(tier1Model, (p) => {
        notify("model-tier1", `${p.status} (${p.percent}%)`, p.percent);
      });

      if (!tier1Installed) {
        throw new Error("ê¸°ë³¸ AI ëª¨ë¸ ì„¤ì¹˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
      }
    } else {
      notify("model-tier1", "ê¸°ë³¸ AI ëª¨ë¸ì´ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤", 100);
    }

    // Step 6: Tier 2 ëª¨ë¸ ì„¤ì¹˜ (full ëª¨ë“œì´ê³  ë©”ëª¨ë¦¬ ì¶©ë¶„í•  ë•Œë§Œ)
    let tier2Installed = false;
    const tier2Model = "qwen3:4b-q4_K_M";

    if (installMode === "full" && device.canRunTier2) {
      notify("model-tier2", "Qwen3-4B (ê³ ê¸‰ ì²˜ë¦¬) ë‹¤ìš´ë¡œë“œ ì¤‘...");

      tier2Installed = await isModelInstalled(tier2Model);

      if (!tier2Installed) {
        tier2Installed = await downloadModel(tier2Model, (p) => {
          notify("model-tier2", `${p.status} (${p.percent}%)`, p.percent);
        });
        // Tier 2 ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (í•„ìˆ˜ ì•„ë‹˜)
      } else {
        notify("model-tier2", "ê³ ê¸‰ AI ëª¨ë¸ì´ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤", 100);
      }
    } else {
      notify(
        "model-tier2",
        device.canRunTier2
          ? "ìµœì†Œ ì„¤ì¹˜ ëª¨ë“œ - ê³ ê¸‰ ëª¨ë¸ ê±´ë„ˆëœ€"
          : `ë©”ëª¨ë¦¬ ë¶€ì¡± (${device.totalMemoryGB}GB) - ê³ ê¸‰ ëª¨ë¸ ê±´ë„ˆëœ€`,
      );
    }

    // Step 7: ì„¤ì¹˜ í™•ì¸
    notify("verifying");

    const version = await getOllamaVersion();
    await verifyInstallation(tier1Model);

    // Step 8: ì™„ë£Œ
    notify("complete");

    const result: InstallResult = {
      success: true,
      tier1Installed,
      tier2Installed,
      ollamaVersion: version || undefined,
      duration: Date.now() - startTime,
    };

    config.onComplete?.(result);
    return result;
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜";

    notify("error", errorMessage);

    const result: InstallResult = {
      success: false,
      tier1Installed: false,
      tier2Installed: false,
      error: errorMessage,
      duration: Date.now() - startTime,
    };

    config.onError?.(error instanceof Error ? error : new Error(errorMessage));
    config.onComplete?.(result);
    return result;
  }
}

/**
 * ì„¤ì¹˜ ê²€ì¦
 */
async function verifyInstallation(modelName: string): Promise<void> {
  // ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­
  try {
    const response = await fetch(`${OLLAMA_API}/api/generate`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        model: modelName,
        prompt: "Hi",
        options: { num_predict: 1 },
      }),
    });

    if (!response.ok) {
      throw new Error("ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨");
    }
  } catch (error) {
    console.warn("ì„¤ì¹˜ ê²€ì¦ ê²½ê³ :", error);
    // ê²€ì¦ ì‹¤íŒ¨í•´ë„ ì§„í–‰ (ì²« ì‹¤í–‰ì‹œ ëŠë¦´ ìˆ˜ ìˆìŒ)
  }
}

// ============================================
// Helper Functions
// ============================================

function sleep(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

function getNextStep(current: InstallStep): InstallStep | null {
  const steps: InstallStep[] = [
    "preparing",
    "checking",
    "downloading",
    "installing",
    "starting",
    "model-tier1",
    "model-tier2",
    "verifying",
    "complete",
  ];
  const index = steps.indexOf(current);
  return index >= 0 && index < steps.length - 1 ? steps[index + 1] : null;
}

async function retryWithBackoff<T>(fn: () => Promise<T>, maxRetries: number): Promise<T> {
  let lastError: Error | null = null;

  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error instanceof Error ? error : new Error(String(error));
      if (i < maxRetries - 1) {
        await sleep(RETRY_DELAY * (i + 1));
      }
    }
  }

  throw lastError;
}

// ============================================
// User-Friendly Wrapper
// ============================================

/**
 * ì‚¬ìš©ì ì¹œí™”ì  ì„¤ì¹˜ ìƒíƒœ í¬ë§·íŒ…
 */
export function formatInstallStatus(status: InstallStatus): string {
  const progressBar = createProgressBar(status.progress);
  return `${status.message}\n${progressBar} ${status.progress}%${status.detail ? `\n${status.detail}` : ""}`;
}

function createProgressBar(percent: number): string {
  const filled = Math.round(percent / 5);
  const empty = 20 - filled;
  return "â–ˆ".repeat(filled) + "â–‘".repeat(empty);
}

/**
 * ì¹´ì¹´ì˜¤í†¡ìš© ì„¤ì¹˜ ì§„í–‰ ë©”ì‹œì§€ í¬ë§·íŒ…
 */
export function formatInstallStatusForKakao(status: InstallStatus): string {
  const emoji = status.step === "complete" ? "âœ…" : status.step === "error" ? "âŒ" : "â³";

  let message = `${emoji} ${status.message}`;

  if (status.progress > 0 && status.progress < 100) {
    message += `\n\nì§„í–‰ë¥ : ${status.progress}%`;
  }

  if (status.detail && status.step !== "complete" && status.step !== "error") {
    message += `\n${status.detail}`;
  }

  return message;
}

/**
 * ì„¤ì¹˜ ê²°ê³¼ ìš”ì•½ ë©”ì‹œì§€
 */
export function formatInstallResult(result: InstallResult): string {
  if (!result.success) {
    return `âŒ MoA AI ì„¤ì¹˜ ì‹¤íŒ¨\n\nì˜¤ë¥˜: ${result.error}\n\nìˆ˜ë™ ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.`;
  }

  const duration = Math.round(result.duration / 1000);

  let message = `ğŸ‰ MoA AI ì„¤ì¹˜ ì™„ë£Œ!\n\n`;
  message += `ğŸ“¦ ì„¤ì¹˜ëœ êµ¬ì„±ìš”ì†Œ:\n`;
  message += `  â€¢ Ollama ${result.ollamaVersion || ""}\n`;
  message += `  â€¢ ê¸°ë³¸ AI (Qwen3-0.6B) âœ…\n`;
  message += `  â€¢ ê³ ê¸‰ AI (Qwen3-4B) ${result.tier2Installed ? "âœ…" : "â­ï¸ ê±´ë„ˆëœ€"}\n`;
  message += `\nâ±ï¸ ì†Œìš” ì‹œê°„: ${duration}ì´ˆ`;

  if (!result.tier2Installed) {
    message += `\n\nğŸ’¡ ê³ ê¸‰ AIëŠ” ë©”ëª¨ë¦¬ 6GB ì´ìƒ ê¸°ê¸°ì—ì„œ ë‚˜ì¤‘ì— ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.`;
  }

  return message;
}

// ============================================
// Exports
// ============================================

export {
  detectDevice,
  isOllamaInstalled,
  isOllamaRunning,
  type DeviceProfile,
  type ModelDownloadProgress,
};
